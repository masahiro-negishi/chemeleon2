# @package _global_
defaults:
  - override /data: mp_amorphous
  - override /ldm_module: ldm_module
  - override /callbacks: default
  - override /logger: wandb
  - override /scheduler: constant
  - override /trainer: default
  - override /paths: default
  - override /hydra: default

trainer:
  max_epochs: 1000
  # strategy: "ddp_find_unused_parameters_true"

data:
  batch_size: 64

ldm_module:
  ldm_ckpt_path: ckpts/mp_120/ldm/ldm_rl_dng_lfczlivd.ckpt

  # lora_configs:
  # r: 16
  # lora_alpha: 32
  # lora_dropout: 0.1
  # target_modules: ["attn.out_proj", "mlp.fc1", "mlp.fc2"]
  # bias: "none"

logger:
  wandb:
    name: "ldm_null_finetuned_from_ldm_rl_dng_alex_mp_20"
    group: "${task_name}/${data.dataset_type}"
    tags: ["ldm", "dng", "null", "finetune", "mp_amorphous"]
